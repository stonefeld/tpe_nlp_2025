# DetecciÃ³n AutomÃ¡tica de Titulares Clickbait en Noticias Digitales

Proyecto de NLP para detectar titulares clickbait utilizando tÃ©cnicas de procesamiento de lenguaje natural y machine learning.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema de clasificaciÃ³n automÃ¡tica para detectar titulares clickbait en noticias digitales utilizando tÃ©cnicas de procesamiento de lenguaje natural (NLP). El objetivo es distinguir entre titulares engaÃ±osos diseÃ±ados para atraer clics y titulares informativos o neutrales.

## ğŸ¯ Objetivos

1. **ClasificaciÃ³n binaria**: Entrenar modelos para clasificar titulares como clickbait o no clickbait
2. **AnÃ¡lisis comparativo**: Evaluar diferentes representaciones de texto (BoW, TF-IDF, embeddings)
3. **Interpretabilidad**: Identificar patrones lingÃ¼Ã­sticos caracterÃ­sticos del clickbait

## ğŸ“Š MetodologÃ­a

### Experimento 1: Modelo ClÃ¡sico (LÃ­nea Base)
- **Representaciones**: Bag of Words (BoW) y TF-IDF
- **Algoritmo**: RegresiÃ³n LogÃ­stica
- **Objetivo**: Establecer lÃ­nea base de rendimiento

### Experimento 2: Modelos Basados en Embeddings
- **GloVe**: Embeddings preentrenados con promediado
- **BERT**: Fine-tuning de modelo transformer
- **Objetivo**: Evaluar mejora con representaciones semÃ¡nticas

### Experimento 3: AnÃ¡lisis LingÃ¼Ã­stico
- **Interpretabilidad**: AnÃ¡lisis de caracterÃ­sticas importantes
- **Patrones**: IdentificaciÃ³n de elementos lingÃ¼Ã­sticos del clickbait
- **Objetivo**: Comprender quÃ© hace clickbait a un titular

## ğŸš€ InstalaciÃ³n

### Requisitos
- Python 3.8+
- pip o uv (gestor de paquetes)

### OpciÃ³n 1: Con UV (Recomendado)

```bash
# Instalar UV
curl -LsSf https://astral.sh/uv/install.sh | sh

# Instalar dependencias
uv sync
```

### OpciÃ³n 2: Con pip

```bash
# Instalar dependencias
pip install pandas numpy scikit-learn matplotlib seaborn nltk tqdm

# Para Experimentos con embeddings (opcional)
pip install gensim transformers torch
```

## ğŸ“ Estructura del Proyecto

```
tpe_nlp_2025/
â”œâ”€â”€ main.py                      # Script principal (ejecuta todos los experimentos)
â”œâ”€â”€ eda.py                       # AnÃ¡lisis exploratorio de datos
â”œâ”€â”€ experimento1.py              # Experimento 1: Modelos clÃ¡sicos
â”œâ”€â”€ experimento2.py              # Experimento 2: Modelos con embeddings
â”œâ”€â”€ experimento3.py              # Experimento 3: AnÃ¡lisis lingÃ¼Ã­stico
â”œâ”€â”€ comparacion_final.py         # ComparaciÃ³n de todos los modelos
â”œâ”€â”€ resumen_y_conclusiones.py    # Resumen y conclusiones del proyecto
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ clickbait_data.csv       # Dataset
â”œâ”€â”€ pyproject.toml               # Dependencias del proyecto
â””â”€â”€ README.md                    # Este archivo
```

## ğŸƒ EjecuciÃ³n

### Ejecutar AnÃ¡lisis Completo

```bash
python main.py
```

Este script ejecutarÃ¡ en orden:
1. AnÃ¡lisis Exploratorio de Datos (EDA)
2. Experimento 1: Modelos ClÃ¡sicos
3. Experimento 2: Modelos con Embeddings
4. Experimento 3: AnÃ¡lisis LingÃ¼Ã­stico
5. ComparaciÃ³n Final de Modelos
6. Resumen y Conclusiones

### Ejecutar Experimentos Individuales

```bash
# AnÃ¡lisis exploratorio
python eda.py

# Experimento 1
python experimento1.py

# Experimento 2
python experimento2.py

# Experimento 3
python experimento3.py

# ComparaciÃ³n final
python comparacion_final.py

# Resumen y conclusiones
python resumen_y_conclusiones.py
```

## ğŸ“ˆ Resultados

Los experimentos generan:

### Visualizaciones (PNG)
- GrÃ¡ficos de distribuciÃ³n de clases
- Comparaciones de modelos
- AnÃ¡lisis de caracterÃ­sticas importantes
- Visualizaciones de patrones lingÃ¼Ã­sticos

### Datos (CSV)
- Resultados de cada experimento
- Tablas comparativas
- CaracterÃ­sticas importantes
- Patrones lingÃ¼Ã­sticos identificados

### DocumentaciÃ³n
- Resumen ejecutivo
- Conclusiones
- Limitaciones del estudio
- Trabajo futuro

## ğŸ“Š Dataset

El proyecto utiliza un dataset de aproximadamente 32,000 titulares de noticias en inglÃ©s, categorizados como:
- **Clickbait (1)**: Titulares engaÃ±osos diseÃ±ados para inducir clics
- **No Clickbait (0)**: Titulares informativos o neutrales

### CaracterÃ­sticas del Dataset:
- DistribuciÃ³n balanceada (50% por clase)
- Longitud promedio: 5-13 palabras por titular
- Fuentes variadas de noticias

## ğŸ” Preprocesamiento

1. **Limpieza**: ConversiÃ³n a minÃºsculas, eliminaciÃ³n de caracteres especiales
2. **TokenizaciÃ³n**: DivisiÃ³n en palabras individuales
3. **Stopwords**: EliminaciÃ³n de palabras comunes
4. **LemmatizaciÃ³n**: ReducciÃ³n de palabras a su raÃ­z

## ğŸ“ MÃ©tricas de EvaluaciÃ³n

- **Accuracy**: PrecisiÃ³n general del modelo
- **Precision**: ProporciÃ³n de verdaderos positivos entre todos los positivos
- **Recall**: ProporciÃ³n de verdaderos positivos detectados
- **F1-Score**: Media armÃ³nica entre precision y recall

## ğŸ“ DocumentaciÃ³n Adicional

- `EXPERIMENTO2_README.md`: DocumentaciÃ³n detallada del Experimento 2
- `EXPERIMENTO3_README.md`: DocumentaciÃ³n detallada del Experimento 3

## ğŸ¤ Contribuciones

Este es un proyecto acadÃ©mico. Para sugerencias o mejoras, por favor crea un issue.

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico.

## ğŸ‘¥ Autores

- Alberto Bendayan
- Theo Shlamovitz
- Theo Stanfield

## ğŸ“š Referencias

- Dataset: [Clickbait Dataset - Kaggle](https://www.kaggle.com/datasets/amananandrai/clickbait-dataset)
- GloVe: [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)
- BERT: [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805)

